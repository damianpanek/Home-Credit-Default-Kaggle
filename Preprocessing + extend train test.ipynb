{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,  GradientBoostingClassifier\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import re\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 201, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-91be97e585b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpos_cash_bal\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'POS_CASH_balance.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprevious_app\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'previous_application.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mapp_merge_extend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'app_merged_extend_bureau.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1067\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 201, saw 3\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "app_train = pd.read_csv('application_train.csv')\n",
    "app_test = pd.read_csv('application_test.csv')\n",
    "bureau  = pd.read_csv('bureau.csv')\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "cred_bal       = pd.read_csv('credit_card_balance.csv')\n",
    "install_pay    = pd.read_csv('installments_payments.csv')\n",
    "pos_cash_bal   = pd.read_csv('POS_CASH_balance.csv')\n",
    "previous_app   = pd.read_csv('previous_application.csv')\n",
    "app_merge_extend = pd.read_csv('app_merged_extend_bureau.txt')\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Czas procesowania %.3f\" %(toc - tic)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app_merge_extend = pd.read_csv('app_merged_extend_bureau.txt', sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_merge_extend = app_merge_extend.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_merge_extend= app_merge_extend.drop(['V1'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application test shape:   (48744, 121)\n",
      "Application train shape:  (307511, 122)\n",
      "Bureau  shape:  (1716428, 17)\n",
      "BUreau  Balance:  (27299925, 3)\n",
      "Credit  Balance shape:  (3840312, 23)\n",
      " Installments Payments shape:  (13605401, 8)\n",
      " Pos cash balance  shape:     (10001358, 8)\n",
      " Previous APplication shape :  (1670214, 37)\n"
     ]
    }
   ],
   "source": [
    "print(\"Application test shape:  \", app_test.shape)\n",
    "print(\"Application train shape: \", app_train.shape)\n",
    "print(\"Bureau  shape: \",  bureau.shape)\n",
    "print(\"BUreau  Balance: \", bureau_balance.shape)\n",
    "print(\"Credit  Balance shape: \", cred_bal.shape )\n",
    "print(\" Installments Payments shape: \", install_pay.shape )\n",
    "print(\" Pos cash balance  shape:    \", pos_cash_bal.shape )\n",
    "print(\" Previous APplication shape : \", previous_app.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate to one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = app_train.loc[:, ['TARGET', 'SK_ID_CURR']]\n",
    "app_train = app_train.drop(['TARGET'] , axis = 1)\n",
    "\n",
    "app_merged = pd.concat([app_train, app_test] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do przeniesienia - app_merge_extend  drop w oparciu o val_to_replace_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_merge_extend = app_merge_extend.merge(y_train, how = 'left', on = 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_extend = app_merge_extend[np.isnan(app_merge_extend.TARGET) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 1403)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_extend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge_extend = app_merge_extend[np.isnan(app_merge_extend.TARGET) == True]\n",
    "test_merge_extend = test_merge_extend.drop(['TARGET'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge_extend = test_merge_extend.drop(var_to_label_enc, axis = 1)\n",
    "train_merge_extend = train_merge_extend.drop(var_to_label_enc, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_extend.shape[0] == app_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_extend.to_csv('train_merge_extend.txt', index_label= False, sep = \"|\")\n",
    "test_merge_extend.to_csv('test_merge_extend.txt', index_label = False, sep = \"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Variables to fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DLa jakich zmiennych zrobic replace dla na\n",
    "var_to_replace_nan = []\n",
    "\n",
    "for i in  app_merged.columns:\n",
    "    #print(\"Zmienna\", i, \"Posiada typ danych \\n\", app_merged.loc[:, i].dtypes)\n",
    "    if app_merged.loc[:, i].dtypes in ('float64', 'int64'):\n",
    "        var_to_replace_nan.append(str(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace na with some guess -9999 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miss na for some absurd value\n",
    "\n",
    "\n",
    "for i in var_to_replace_nan:\n",
    "    \n",
    "    app_merged.loc[:, i]  = app_merged.loc[:, i].fillna(-9999)\n",
    "    app_merged.loc[:, i]   = app_merged.loc[:, i].fillna(-9999)\n",
    "    \n",
    "    #print(\"check:\", i,  \"\\n\", sum(np.isnan(app_merged.loc[:, i]))/app_merged.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIczba unikalnych poziomow dla object dtype\n",
    "var_to_label_enc = []\n",
    "\n",
    "for i in app_merged.columns:\n",
    "    #print(\"Badania dla\", i)\n",
    "    if app_merged.loc[:, i].dtypes == \"object\":\n",
    "        #print(i, \"To object app\")\n",
    "        var_to_label_enc.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in var_to_label_enc:\n",
    "    lbl = LabelEncoder()\n",
    "    app_merged.loc[:, i + str('_enc')] = lbl.fit_transform(app_merged[i].astype(str))\n",
    "    #app_test.loc[:, i]  = lbl.fit_transform(app_train[i].fillna('NaN'))\n",
    "    #print(\"poprawnie przeprowadzone dla \\n\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexes - Train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train = app_merged.index[app_merged.SK_ID_CURR.isin(y_train.SK_ID_CURR) ]\n",
    "ind_test  = app_merged.index[-ind_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
       "                 8,      9,\n",
       "            ...\n",
       "            307501, 307502, 307503, 307504, 307505, 307506, 307507, 307508,\n",
       "            307509, 307510],\n",
       "           dtype='int64', length=307511)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_extend = app_merge_extend.iloc[ind_train]\n",
    "app_test_extend  = app_merge_extend.iloc[-ind_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "app_train_extend.TARGET = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TARGET'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2524\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2525\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TARGET'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-fb863e4a08c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp_train_extend\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TARGET'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3842\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3843\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3844\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2525\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2527\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TARGET'"
     ]
    }
   ],
   "source": [
    "pd.crosstab(app_train_extend['TARGET'], columns = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>100007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>100008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>100009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>100010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>100011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>100012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>100014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>100015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>100017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>100018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>100019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>100020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>100021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>100022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>100023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>100024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>100025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>100026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>100027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>100029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>100030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>100031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>100032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>100033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>100034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307481</th>\n",
       "      <td>1</td>\n",
       "      <td>456225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307482</th>\n",
       "      <td>0</td>\n",
       "      <td>456226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307483</th>\n",
       "      <td>0</td>\n",
       "      <td>456227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307484</th>\n",
       "      <td>0</td>\n",
       "      <td>456228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307485</th>\n",
       "      <td>0</td>\n",
       "      <td>456229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307486</th>\n",
       "      <td>0</td>\n",
       "      <td>456230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307487</th>\n",
       "      <td>0</td>\n",
       "      <td>456231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307488</th>\n",
       "      <td>0</td>\n",
       "      <td>456232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307489</th>\n",
       "      <td>1</td>\n",
       "      <td>456233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307490</th>\n",
       "      <td>0</td>\n",
       "      <td>456234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307491</th>\n",
       "      <td>0</td>\n",
       "      <td>456235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307492</th>\n",
       "      <td>0</td>\n",
       "      <td>456236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307493</th>\n",
       "      <td>0</td>\n",
       "      <td>456237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307494</th>\n",
       "      <td>0</td>\n",
       "      <td>456238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307495</th>\n",
       "      <td>0</td>\n",
       "      <td>456239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307496</th>\n",
       "      <td>0</td>\n",
       "      <td>456240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307497</th>\n",
       "      <td>0</td>\n",
       "      <td>456241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307498</th>\n",
       "      <td>0</td>\n",
       "      <td>456242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307499</th>\n",
       "      <td>0</td>\n",
       "      <td>456243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307500</th>\n",
       "      <td>0</td>\n",
       "      <td>456244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307501</th>\n",
       "      <td>0</td>\n",
       "      <td>456245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307502</th>\n",
       "      <td>0</td>\n",
       "      <td>456246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307503</th>\n",
       "      <td>0</td>\n",
       "      <td>456247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307504</th>\n",
       "      <td>0</td>\n",
       "      <td>456248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307505</th>\n",
       "      <td>0</td>\n",
       "      <td>456249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>0</td>\n",
       "      <td>456251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>0</td>\n",
       "      <td>456252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>0</td>\n",
       "      <td>456253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>1</td>\n",
       "      <td>456254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>0</td>\n",
       "      <td>456255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TARGET  SK_ID_CURR\n",
       "0            1      100002\n",
       "1            0      100003\n",
       "2            0      100004\n",
       "3            0      100006\n",
       "4            0      100007\n",
       "5            0      100008\n",
       "6            0      100009\n",
       "7            0      100010\n",
       "8            0      100011\n",
       "9            0      100012\n",
       "10           0      100014\n",
       "11           0      100015\n",
       "12           0      100016\n",
       "13           0      100017\n",
       "14           0      100018\n",
       "15           0      100019\n",
       "16           0      100020\n",
       "17           0      100021\n",
       "18           0      100022\n",
       "19           0      100023\n",
       "20           0      100024\n",
       "21           0      100025\n",
       "22           0      100026\n",
       "23           0      100027\n",
       "24           0      100029\n",
       "25           0      100030\n",
       "26           1      100031\n",
       "27           0      100032\n",
       "28           0      100033\n",
       "29           0      100034\n",
       "...        ...         ...\n",
       "307481       1      456225\n",
       "307482       0      456226\n",
       "307483       0      456227\n",
       "307484       0      456228\n",
       "307485       0      456229\n",
       "307486       0      456230\n",
       "307487       0      456231\n",
       "307488       0      456232\n",
       "307489       1      456233\n",
       "307490       0      456234\n",
       "307491       0      456235\n",
       "307492       0      456236\n",
       "307493       0      456237\n",
       "307494       0      456238\n",
       "307495       0      456239\n",
       "307496       0      456240\n",
       "307497       0      456241\n",
       "307498       0      456242\n",
       "307499       0      456243\n",
       "307500       0      456244\n",
       "307501       0      456245\n",
       "307502       0      456246\n",
       "307503       0      456247\n",
       "307504       0      456248\n",
       "307505       0      456249\n",
       "307506       0      456251\n",
       "307507       0      456252\n",
       "307508       0      456253\n",
       "307509       1      456254\n",
       "307510       0      456255\n",
       "\n",
       "[307511 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train_extend.TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregates \n",
    "- bureau credit\n",
    "- previous app\n",
    "\n",
    "\n",
    "Information about client previous behaviour. Dummy variable  if client has mortgage/loan/credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_merged.to_csv('app_merged.txt', sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: \n",
      " 8.112\n"
     ]
    }
   ],
   "source": [
    "toc = time.time()\n",
    "\n",
    "\n",
    "funs = ['sum', 'mean', 'std', 'median', 'max']\n",
    "\n",
    "bureau_credit_activity = bureau.groupby(['SK_ID_CURR', \n",
    "                                         'CREDIT_ACTIVE']).agg({'SK_ID_CURR' : 'count',\n",
    "                                         'CREDIT_ACTIVE' : 'count',\n",
    "                                         'DAYS_CREDIT' : funs, \n",
    "                                         'AMT_CREDIT_MAX_OVERDUE' : funs ,\n",
    "                                         'AMT_CREDIT_SUM'          : funs })\n",
    "\n",
    "\n",
    "\n",
    "bureau_credit_type = bureau.groupby(['SK_ID_CURR',\n",
    "                                        'CREDIT_TYPE']).agg({'SK_ID_CURR' : 'count',\n",
    "                                        'CREDIT_TYPE' : 'count'         ,\n",
    "                                        'DAYS_CREDIT'            : funs , \n",
    "                                        'AMT_CREDIT_MAX_OVERDUE' : funs , \n",
    "                                        'AMT_CREDIT_SUM'         : funs })\n",
    "\n",
    "\n",
    "previous_app_contract_type = previous_app.groupby(['SK_ID_CURR', \n",
    "                                                  'NAME_CONTRACT_TYPE']).agg({'SK_ID_CURR' : 'count',\n",
    "                                                  'NAME_CONTRACT_TYPE' : 'count' ,\n",
    "                                                  'AMT_ANNUITY' : funs, \n",
    "                                                  'AMT_APPLICATION' : funs, \n",
    "                                                  'AMT_CREDIT'      : funs,\n",
    "                                                  'AMT_DOWN_PAYMENT' : funs                     \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "previous_app_aggr = previous_app.groupby(['SK_ID_CURR']).agg({\n",
    "    'SK_ID_CURR' : 'count', \n",
    "    'AMT_ANNUITY' : funs, \n",
    "    'AMT_APPLICATION' : funs, \n",
    "    'AMT_CREDIT'      : funs, \n",
    "    'AMT_DOWN_PAYMENT' : funs\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "client_has_mortgage = bureau[bureau.CREDIT_TYPE  == 'Mortgage']\n",
    "client_has_mortgage['CLIENT_HAS_MORTGAGE'] = 1\n",
    "\n",
    "client_has_cash_loan = previous_app.loc[previous_app.NAME_CONTRACT_TYPE == \"Cash loans\", ['SK_ID_CURR', 'NAME_CONTRACT_TYPE']]\n",
    "client_has_cash_loan['CLIENT_HAS_CASH_LOAN'] = 1\n",
    "\n",
    "\n",
    "\n",
    "client_has_consumer_loan = previous_app.loc[previous_app.NAME_CONTRACT_TYPE == 'Consumer loans', \n",
    "                                           ['SK_ID_CURR', 'NAME_CONTRACT_TYPE']]\n",
    "client_has_consumer_loan['CLIENT_HAS_CONSUMER_LOAN'] = 1\n",
    "\n",
    "\n",
    "client_has_mortgage = client_has_mortgage.loc[:, ['SK_ID_CURR', 'CLIENT_HAS_MORTGAGE'] ]\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(\"Processing time: \\n %.3f\" % (tic-toc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: \n",
      " 9.136\n"
     ]
    }
   ],
   "source": [
    "toc = time.time() \n",
    "\n",
    "app_merged = app_merged.merge(client_has_cash_loan, on = 'SK_ID_CURR', how = 'left' , suffixes= ['global', 'cash_loan'])\n",
    "app_merged = app_merged.merge(client_has_consumer_loan, on = 'SK_ID_CURR', how = 'left', suffixes = ['global' ,'consumer_loan'])\n",
    "\n",
    "app_merged =  app_merged.merge(client_has_mortgage, on = 'SK_ID_CURR', \n",
    "                               how = 'left' , suffixes = ['global', 'mortgages'] )\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(\"Processing time: \\n %.3f\" % (tic - toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_merged.loc[:, ['CLIENT_HAS_CASH_LOAN', 'CLIENT_HAS_CONSUMER_LOAN', 'CLIENT_HAS_MORTGAGE']] = app_merged.loc[:, ['CLIENT_HAS_CASH_LOAN', 'CLIENT_HAS_CONSUMER_LOAN', 'CLIENT_HAS_MORTGAGE']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['SK_ID_CURR', 'DAYS_CREDIT', 'AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM'], ['count', 'max', 'mean', 'median', 'std', 'sum']],\n",
       "           labels=[[0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_credit_activity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['SK_ID_CURR', 'CREDIT_ACTIVE', 'DAYS_CREDIT', 'AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM'], ['count', 'max', 'mean', 'median', 'std', 'sum']],\n",
       "           labels=[[0, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4], [0, 0, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_credit_activity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bureau_credit_max_ovd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['ind'] =  test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['ind'] =  test['ind'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMT_CREDIT_MAX_OVERDUE_sum       float64\n",
       "AMT_CREDIT_MAX_OVERDUE_mean      float64\n",
       "AMT_CREDIT_MAX_OVERDUE_std       float64\n",
       "AMT_CREDIT_MAX_OVERDUE_median    float64\n",
       "AMT_CREDIT_MAX_OVERDUE_max       float64\n",
       "ind                               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['ind'] = test['ind'].replace(to_replace = ',', value = \" \", inplace = True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR  CREDIT_ACTIVE\n",
       "100001      Active           None\n",
       "            Closed           None\n",
       "100002      Active           None\n",
       "            Closed           None\n",
       "100003      Active           None\n",
       "            Closed           None\n",
       "100004      Closed           None\n",
       "100005      Active           None\n",
       "            Closed           None\n",
       "100007      Closed           None\n",
       "100008      Active           None\n",
       "            Closed           None\n",
       "100009      Active           None\n",
       "            Closed           None\n",
       "100010      Active           None\n",
       "            Closed           None\n",
       "100011      Closed           None\n",
       "100013      Closed           None\n",
       "100014      Active           None\n",
       "            Closed           None\n",
       "100015      Closed           None\n",
       "100016      Active           None\n",
       "            Closed           None\n",
       "100017      Closed           None\n",
       "100019      Active           None\n",
       "100020      Active           None\n",
       "            Closed           None\n",
       "100022      Active           None\n",
       "100023      Active           None\n",
       "            Closed           None\n",
       "                             ... \n",
       "456235      Closed           None\n",
       "456236      Active           None\n",
       "            Closed           None\n",
       "456237      Closed           None\n",
       "456238      Active           None\n",
       "            Closed           None\n",
       "456239      Active           None\n",
       "            Closed           None\n",
       "456240      Active           None\n",
       "            Closed           None\n",
       "456241      Active           None\n",
       "            Closed           None\n",
       "456242      Active           None\n",
       "456243      Active           None\n",
       "            Closed           None\n",
       "456244      Active           None\n",
       "            Closed           None\n",
       "456246      Active           None\n",
       "            Closed           None\n",
       "456247      Active           None\n",
       "            Closed           None\n",
       "456249      Active           None\n",
       "            Closed           None\n",
       "456250      Active           None\n",
       "            Closed           None\n",
       "456253      Active           None\n",
       "            Closed           None\n",
       "456254      Closed           None\n",
       "456255      Active           None\n",
       "            Closed           None\n",
       "Name: ind, Length: 525782, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_activity_d_cred = bureau_credit_activity[ 'DAYS_CREDIT' ]\n",
    "bureau_credit_max_ovd  = bureau_credit_activity[ 'AMT_CREDIT_MAX_OVERDUE' ]\n",
    "bureau_amt_credit      = bureau_credit_activity[ 'AMT_CREDIT_SUM' ]\n",
    "\n",
    "max_overdue_cols = [ \"AMT_CREDIT_MAX_OVERDUE_\" + str(i) for i in bureau_credit_activity[ 'AMT_CREDIT_MAX_OVERDUE' ].columns ]\n",
    "amt_credit_cols  = [ \"AMT_CREDIT_\" + str(i) for i in bureau_credit_activity[ 'AMT_CREDIT_SUM' ].columns ]\n",
    "days_credit_cols = [ \"DAYS_CREDIT_\"  + str(i) for i in bureau_credit_activity[ 'DAYS_CREDIT' ].columns ]\n",
    "\n",
    "bureau_activity_d_cred.columns = days_credit_cols\n",
    "bureau_credit_max_ovd.columns = max_overdue_cols \n",
    "bureau_amt_credit.columns = amt_credit_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bureau_credit_activity['DAYS_CREDIT'].columns =  days_credit_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bureau activity joins to app_merged \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DAYS_CREDIT_sum', 'DAYS_CREDIT_mean', 'DAYS_CREDIT_std',\n",
       "       'DAYS_CREDIT_median', 'DAYS_CREDIT_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype - baseline model check\n",
    "\n",
    "- Cross Validation\n",
    "- Stratified K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_enc = app_merged.loc[:max(ind_train), :]\n",
    "app_test_enc = app_merged.loc[max(ind_train):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_enc = app_train_enc.drop(var_to_label_enc, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_tr, y_val = train_test_split(app_train_enc, y_train.TARGET,  \n",
    "                                                     random_state = 321, \n",
    "                                                     test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treningowy zestaw danych\", X_train.shape[1])\n",
    "print(\"Walidacyjny zestaw danych\", X_valid.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(X_train, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba = model.predict_proba(X_valid)[:, 0]\n",
    "test_pred   = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(test_pred, columns = 'count')/len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index()\n",
    "y_tr = y_tr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "kfold = KFold(n_splits = 10, \n",
    "                       random_state = 321).split(X_train, y_tr.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for k, (train, valid) in enumerate(kfold):\n",
    "    print(max(train), min(train))\n",
    "    print(\"Valid \\n\", max(valid), min(valid))\n",
    "    rf.fit(X_train.loc[train, :], y_tr.TARGET[train] )\n",
    "    pred = rf.predict(X_train.loc[valid, :])\n",
    "    score = roc_auc_score(pred , y_tr.TARGET[valid])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_tr.TARGET[train]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kfold = KFold(n_splits = 10, \n",
    "                       random_state = 321).split(X_train, y_tr.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import AdaBoostClassifier\n",
    "\n",
    "\n",
    "ada_fit = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "scores_ada = []\n",
    "\n",
    "for k, (train, valid) in enumerate(kfold):\n",
    "    print(max(train), min(train))\n",
    "    print(\"Valid \\n\", max(valid), min(valid))\n",
    "    ada_fit.fit(X_train.loc[train, :], y_tr.TARGET[train] )\n",
    "    pred = ada_fit.predict(X_train.loc[valid, :])\n",
    "    score = roc_auc_score(pred , y_tr.TARGET[valid])\n",
    "    scores_ada.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_tr.TARGET[train]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 321).split(X_train, y_tr.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scores_gbm = []\n",
    "\n",
    "for k, (train, valid) in enumerate(kfold):\n",
    "    print(max(train), min(train))\n",
    "    print(\"Valid \\n\", max(valid), min(valid))\n",
    "    gbm.fit(X_train.loc[train, :], y_tr.TARGET[train] )\n",
    "    pred = gbm.predict(X_train.loc[valid, :])\n",
    "    score = roc_auc_score(pred , y_tr.TARGET[valid])\n",
    "    scores_gbm.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_tr.TARGET[train]), score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
