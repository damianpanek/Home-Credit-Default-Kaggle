{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,  GradientBoostingClassifier\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import re\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas procesowania 47.108\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "app_train = pd.read_csv('application_train.csv')\n",
    "app_test = pd.read_csv('application_test.csv')\n",
    "bureau  = pd.read_csv('bureau.csv')\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "cred_bal       = pd.read_csv('credit_card_balance.csv')\n",
    "install_pay    = pd.read_csv('installments_payments.csv')\n",
    "pos_cash_bal   = pd.read_csv('POS_CASH_balance.csv')\n",
    "previous_app   = pd.read_csv('previous_application.csv')\n",
    "\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Czas procesowania %.3f\" %(toc - tic)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application test shape:   (48744, 121)\n",
      "Application train shape:  (307511, 122)\n",
      "Bureau  shape:  (1716428, 17)\n",
      "BUreau  Balance:  (27299925, 3)\n",
      "Credit  Balance shape:  (3840312, 23)\n",
      " Installments Payments shape:  (13605401, 8)\n",
      " Pos cash balance  shape:     (10001358, 8)\n",
      " Previous APplication shape :  (1670214, 37)\n"
     ]
    }
   ],
   "source": [
    "print(\"Application test shape:  \", app_test.shape)\n",
    "print(\"Application train shape: \", app_train.shape)\n",
    "print(\"Bureau  shape: \",  bureau.shape)\n",
    "print(\"BUreau  Balance: \", bureau_balance.shape)\n",
    "print(\"Credit  Balance shape: \", cred_bal.shape )\n",
    "print(\" Installments Payments shape: \", install_pay.shape )\n",
    "print(\" Pos cash balance  shape:    \", pos_cash_bal.shape )\n",
    "print(\" Previous APplication shape : \", previous_app.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate to one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = app_train.loc[:, ['TARGET', 'SK_ID_CURR']]\n",
    "app_train = app_train.drop(['TARGET'] , axis = 1)\n",
    "\n",
    "app_merged = pd.concat([app_train, app_test] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Variables to fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DLa jakich zmiennych zrobic replace dla na\n",
    "var_to_replace_nan = []\n",
    "\n",
    "for i in  app_merged.columns:\n",
    "    #print(\"Zmienna\", i, \"Posiada typ danych \\n\", app_merged.loc[:, i].dtypes)\n",
    "    if app_merged.loc[:, i].dtypes in ('float64', 'int64'):\n",
    "        var_to_replace_nan.append(str(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace na with some guess -9999 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miss na for some absurd value\n",
    "\n",
    "\n",
    "for i in var_to_replace_nan:\n",
    "    \n",
    "    app_merged.loc[:, i]  = app_merged.loc[:, i].fillna(-9999)\n",
    "    app_merged.loc[:, i]   = app_merged.loc[:, i].fillna(-9999)\n",
    "    \n",
    "    #print(\"check:\", i,  \"\\n\", sum(np.isnan(app_merged.loc[:, i]))/app_merged.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIczba unikalnych poziomow dla object dtype\n",
    "var_to_label_enc = []\n",
    "\n",
    "for i in app_merged.columns:\n",
    "    #print(\"Badania dla\", i)\n",
    "    if app_merged.loc[:, i].dtypes == \"object\":\n",
    "        #print(i, \"To object app\")\n",
    "        var_to_label_enc.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in var_to_label_enc:\n",
    "    lbl = LabelEncoder()\n",
    "    app_merged.loc[:, i + str('_enc')] = lbl.fit_transform(app_merged[i].astype(str))\n",
    "    #app_test.loc[:, i]  = lbl.fit_transform(app_train[i].fillna('NaN'))\n",
    "    #print(\"poprawnie przeprowadzone dla \\n\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexes - Train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train = app_merged.index[app_merged.SK_ID_CURR.isin(y_train.SK_ID_CURR) ]\n",
    "ind_test  = app_merged.index[-ind_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregates \n",
    "- bureau credit\n",
    "- previous app\n",
    "\n",
    "\n",
    "Information about client previous behaviour. Dummy variable  if client has mortgage/loan/credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_merged.to_csv('app_merged.txt', sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: \n",
      " 8.112\n"
     ]
    }
   ],
   "source": [
    "toc = time.time()\n",
    "\n",
    "\n",
    "funs = ['sum', 'mean', 'std', 'median', 'max']\n",
    "\n",
    "bureau_credit_activity = bureau.groupby(['SK_ID_CURR', \n",
    "                                         'CREDIT_ACTIVE']).agg({'SK_ID_CURR' : 'count',\n",
    "                                         'CREDIT_ACTIVE' : 'count',\n",
    "                                         'DAYS_CREDIT' : funs, \n",
    "                                         'AMT_CREDIT_MAX_OVERDUE' : funs ,\n",
    "                                         'AMT_CREDIT_SUM'          : funs })\n",
    "\n",
    "\n",
    "\n",
    "bureau_credit_type = bureau.groupby(['SK_ID_CURR',\n",
    "                                        'CREDIT_TYPE']).agg({'SK_ID_CURR' : 'count',\n",
    "                                        'CREDIT_TYPE' : 'count'         ,\n",
    "                                        'DAYS_CREDIT'            : funs , \n",
    "                                        'AMT_CREDIT_MAX_OVERDUE' : funs , \n",
    "                                        'AMT_CREDIT_SUM'         : funs })\n",
    "\n",
    "\n",
    "previous_app_contract_type = previous_app.groupby(['SK_ID_CURR', \n",
    "                                                  'NAME_CONTRACT_TYPE']).agg({'SK_ID_CURR' : 'count',\n",
    "                                                  'NAME_CONTRACT_TYPE' : 'count' ,\n",
    "                                                  'AMT_ANNUITY' : funs, \n",
    "                                                  'AMT_APPLICATION' : funs, \n",
    "                                                  'AMT_CREDIT'      : funs,\n",
    "                                                  'AMT_DOWN_PAYMENT' : funs                     \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "previous_app_aggr = previous_app.groupby(['SK_ID_CURR']).agg({\n",
    "    'SK_ID_CURR' : 'count', \n",
    "    'AMT_ANNUITY' : funs, \n",
    "    'AMT_APPLICATION' : funs, \n",
    "    'AMT_CREDIT'      : funs, \n",
    "    'AMT_DOWN_PAYMENT' : funs\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "client_has_mortgage = bureau[bureau.CREDIT_TYPE  == 'Mortgage']\n",
    "client_has_mortgage['CLIENT_HAS_MORTGAGE'] = 1\n",
    "\n",
    "client_has_cash_loan = previous_app.loc[previous_app.NAME_CONTRACT_TYPE == \"Cash loans\", ['SK_ID_CURR', 'NAME_CONTRACT_TYPE']]\n",
    "client_has_cash_loan['CLIENT_HAS_CASH_LOAN'] = 1\n",
    "\n",
    "\n",
    "\n",
    "client_has_consumer_loan = previous_app.loc[previous_app.NAME_CONTRACT_TYPE == 'Consumer loans', \n",
    "                                           ['SK_ID_CURR', 'NAME_CONTRACT_TYPE']]\n",
    "client_has_consumer_loan['CLIENT_HAS_CONSUMER_LOAN'] = 1\n",
    "\n",
    "\n",
    "client_has_mortgage = client_has_mortgage.loc[:, ['SK_ID_CURR', 'CLIENT_HAS_MORTGAGE'] ]\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(\"Processing time: \\n %.3f\" % (tic-toc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: \n",
      " 9.136\n"
     ]
    }
   ],
   "source": [
    "toc = time.time() \n",
    "\n",
    "app_merged = app_merged.merge(client_has_cash_loan, on = 'SK_ID_CURR', how = 'left' , suffixes= ['global', 'cash_loan'])\n",
    "app_merged = app_merged.merge(client_has_consumer_loan, on = 'SK_ID_CURR', how = 'left', suffixes = ['global' ,'consumer_loan'])\n",
    "\n",
    "app_merged =  app_merged.merge(client_has_mortgage, on = 'SK_ID_CURR', \n",
    "                               how = 'left' , suffixes = ['global', 'mortgages'] )\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(\"Processing time: \\n %.3f\" % (tic - toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_merged.loc[:, ['CLIENT_HAS_CASH_LOAN', 'CLIENT_HAS_CONSUMER_LOAN', 'CLIENT_HAS_MORTGAGE']] = app_merged.loc[:, ['CLIENT_HAS_CASH_LOAN', 'CLIENT_HAS_CONSUMER_LOAN', 'CLIENT_HAS_MORTGAGE']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['SK_ID_CURR', 'DAYS_CREDIT', 'AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM'], ['count', 'max', 'mean', 'median', 'std', 'sum']],\n",
       "           labels=[[0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_credit_activity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['SK_ID_CURR', 'CREDIT_ACTIVE', 'DAYS_CREDIT', 'AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM'], ['count', 'max', 'mean', 'median', 'std', 'sum']],\n",
       "           labels=[[0, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4], [0, 0, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1, 5, 2, 4, 3, 1]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_credit_activity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bureau_credit_max_ovd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['ind'] =  test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['ind'] =  test['ind'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMT_CREDIT_MAX_OVERDUE_sum       float64\n",
       "AMT_CREDIT_MAX_OVERDUE_mean      float64\n",
       "AMT_CREDIT_MAX_OVERDUE_std       float64\n",
       "AMT_CREDIT_MAX_OVERDUE_median    float64\n",
       "AMT_CREDIT_MAX_OVERDUE_max       float64\n",
       "ind                               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['ind'] = test['ind'].replace(to_replace = ',', value = \" \", inplace = True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR  CREDIT_ACTIVE\n",
       "100001      Active           None\n",
       "            Closed           None\n",
       "100002      Active           None\n",
       "            Closed           None\n",
       "100003      Active           None\n",
       "            Closed           None\n",
       "100004      Closed           None\n",
       "100005      Active           None\n",
       "            Closed           None\n",
       "100007      Closed           None\n",
       "100008      Active           None\n",
       "            Closed           None\n",
       "100009      Active           None\n",
       "            Closed           None\n",
       "100010      Active           None\n",
       "            Closed           None\n",
       "100011      Closed           None\n",
       "100013      Closed           None\n",
       "100014      Active           None\n",
       "            Closed           None\n",
       "100015      Closed           None\n",
       "100016      Active           None\n",
       "            Closed           None\n",
       "100017      Closed           None\n",
       "100019      Active           None\n",
       "100020      Active           None\n",
       "            Closed           None\n",
       "100022      Active           None\n",
       "100023      Active           None\n",
       "            Closed           None\n",
       "                             ... \n",
       "456235      Closed           None\n",
       "456236      Active           None\n",
       "            Closed           None\n",
       "456237      Closed           None\n",
       "456238      Active           None\n",
       "            Closed           None\n",
       "456239      Active           None\n",
       "            Closed           None\n",
       "456240      Active           None\n",
       "            Closed           None\n",
       "456241      Active           None\n",
       "            Closed           None\n",
       "456242      Active           None\n",
       "456243      Active           None\n",
       "            Closed           None\n",
       "456244      Active           None\n",
       "            Closed           None\n",
       "456246      Active           None\n",
       "            Closed           None\n",
       "456247      Active           None\n",
       "            Closed           None\n",
       "456249      Active           None\n",
       "            Closed           None\n",
       "456250      Active           None\n",
       "            Closed           None\n",
       "456253      Active           None\n",
       "            Closed           None\n",
       "456254      Closed           None\n",
       "456255      Active           None\n",
       "            Closed           None\n",
       "Name: ind, Length: 525782, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_activity_d_cred = bureau_credit_activity[ 'DAYS_CREDIT' ]\n",
    "bureau_credit_max_ovd  = bureau_credit_activity[ 'AMT_CREDIT_MAX_OVERDUE' ]\n",
    "bureau_amt_credit      = bureau_credit_activity[ 'AMT_CREDIT_SUM' ]\n",
    "\n",
    "max_overdue_cols = [ \"AMT_CREDIT_MAX_OVERDUE_\" + str(i) for i in bureau_credit_activity[ 'AMT_CREDIT_MAX_OVERDUE' ].columns ]\n",
    "amt_credit_cols  = [ \"AMT_CREDIT_\" + str(i) for i in bureau_credit_activity[ 'AMT_CREDIT_SUM' ].columns ]\n",
    "days_credit_cols = [ \"DAYS_CREDIT_\"  + str(i) for i in bureau_credit_activity[ 'DAYS_CREDIT' ].columns ]\n",
    "\n",
    "bureau_activity_d_cred.columns = days_credit_cols\n",
    "bureau_credit_max_ovd.columns = max_overdue_cols \n",
    "bureau_amt_credit.columns = amt_credit_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bureau_credit_activity['DAYS_CREDIT'].columns =  days_credit_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bureau activity joins to app_merged \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DAYS_CREDIT_sum', 'DAYS_CREDIT_mean', 'DAYS_CREDIT_std',\n",
       "       'DAYS_CREDIT_median', 'DAYS_CREDIT_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype - baseline model check\n",
    "\n",
    "- Cross Validation\n",
    "- Stratified K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_enc = app_merged.loc[:max(ind_train), :]\n",
    "app_test_enc = app_merged.loc[max(ind_train):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_enc = app_train_enc.drop(var_to_label_enc, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_tr, y_val = train_test_split(app_train_enc, y_train.TARGET,  \n",
    "                                                     random_state = 321, \n",
    "                                                     test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treningowy zestaw danych\", X_train.shape[1])\n",
    "print(\"Walidacyjny zestaw danych\", X_valid.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(X_train, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba = model.predict_proba(X_valid)[:, 0]\n",
    "test_pred   = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(test_pred, columns = 'count')/len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index()\n",
    "y_tr = y_tr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "kfold = KFold(n_splits = 10, \n",
    "                       random_state = 321).split(X_train, y_tr.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for k, (train, valid) in enumerate(kfold):\n",
    "    print(max(train), min(train))\n",
    "    print(\"Valid \\n\", max(valid), min(valid))\n",
    "    rf.fit(X_train.loc[train, :], y_tr.TARGET[train] )\n",
    "    pred = rf.predict(X_train.loc[valid, :])\n",
    "    score = roc_auc_score(pred , y_tr.TARGET[valid])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_tr.TARGET[train]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kfold = KFold(n_splits = 10, \n",
    "                       random_state = 321).split(X_train, y_tr.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import AdaBoostClassifier\n",
    "\n",
    "\n",
    "ada_fit = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "scores_ada = []\n",
    "\n",
    "for k, (train, valid) in enumerate(kfold):\n",
    "    print(max(train), min(train))\n",
    "    print(\"Valid \\n\", max(valid), min(valid))\n",
    "    ada_fit.fit(X_train.loc[train, :], y_tr.TARGET[train] )\n",
    "    pred = ada_fit.predict(X_train.loc[valid, :])\n",
    "    score = roc_auc_score(pred , y_tr.TARGET[valid])\n",
    "    scores_ada.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_tr.TARGET[train]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 321).split(X_train, y_tr.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scores_gbm = []\n",
    "\n",
    "for k, (train, valid) in enumerate(kfold):\n",
    "    print(max(train), min(train))\n",
    "    print(\"Valid \\n\", max(valid), min(valid))\n",
    "    gbm.fit(X_train.loc[train, :], y_tr.TARGET[train] )\n",
    "    pred = gbm.predict(X_train.loc[valid, :])\n",
    "    score = roc_auc_score(pred , y_tr.TARGET[valid])\n",
    "    scores_gbm.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_tr.TARGET[train]), score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
